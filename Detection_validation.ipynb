{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Preprocessing import remove_mentions_and_urls, remove_emojis, remove_english_words\n",
    "\n",
    "from Detect.IndicLID.Inference.ai4bharat.IndicLID import IndicLID                           # Detection Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "IndicLID_model = IndicLID(input_threshold = 0.5, roman_lid_threshold = 0.6)                 # Loading Model with recommended Hyperparams\n",
    "\n",
    "detection_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "\n",
    "input_file_path = r'C:\\Users\\useer\\Downloads\\Twitter_Mention_Biweekly_16_31_Jan2023.xlsx'\n",
    "input_df = pd.read_excel(input_file_path)\n",
    "input_df['Preprocessed_text'] = input_df['Tweet'].astype(str).apply(remove_mentions_and_urls).apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection model\n",
    "detected_tuples = IndicLID_model.batch_predict(input_df['Preprocessed_text'].tolist(), batch_size = detection_batch_size)\n",
    "\n",
    "# Turn detection out (in tuple format) to df\n",
    "detected_df = pd.DataFrame(detected_tuples, columns = ['Text', 'Language_pred', 'Certainity', 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection tags classification\n",
    "\n",
    "hindi_categories = ['hin_Deva', 'mai_Deva', 'mar_Deva', 'san_Deva', 'hin_Latn', 'kas_Deva', 'pan_Latn', 'kok_Deva', 'brx_Deva', 'doi_Deva', 'urd_Latn', 'mai_Latn', 'brx_Latn', 'nep_Deva', 'asm_Latn']\n",
    "ben_categories = ['ben_Beng', 'asm_Beng', 'ben_Latn', 'mni_Beng', 'sat_Olch']\n",
    "tel_categories = ['tel_Telu', 'tel_Latn']\n",
    "eng_categories = ['eng_Latn', 'mni_Latn', 'kok_Latn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation before english character removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_df['Language_true'] = input_df['Label'].tolist()\n",
    "\n",
    "detected_df = detected_df[~detected_df['Language_pred'].isin(['mni_Meti', 'sat_Olch'])]     # mni_Meti corresponds to empty string and sat_olch to only punctuations\n",
    "\n",
    "eval_df = detected_df\n",
    "\n",
    "# Estimating the count of correct predictions\n",
    "correct_hindi_count = ((eval_df['Language_true'] == 'Hindi') & (eval_df['Language_pred'].isin(hindi_categories))).sum()\n",
    "correct_ben_count = ((eval_df['Language_true'] == 'Bengali') & (eval_df['Language_pred'].isin(ben_categories))).sum()\n",
    "correct_tel_count = ((eval_df['Language_true'] == 'Telugu') & (eval_df['Language_pred'].isin(tel_categories))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi Prediction accuracy: 97.86% out of 234\n",
      "Bengali Prediction accuracy: 100.0% out of 227\n",
      "Telugu Prediction accuracy: 97.4% out of 231\n",
      "Overall accuracy: 98.41% out of 692\n"
     ]
    }
   ],
   "source": [
    "# Estimating accuracy in each language\n",
    "\n",
    "hindi_acc = str(round(correct_hindi_count * 100 / ((eval_df['Language_true'] == 'Hindi').sum()), 2)) + '%'\n",
    "ben_acc = str(round(correct_ben_count * 100 / ((eval_df['Language_true'] == 'Bengali').sum()), 2)) + '%'\n",
    "tel_acc = str(round(correct_tel_count * 100 / ((eval_df['Language_true'] == 'Telugu').sum()), 2)) + '%'\n",
    "total_valid = (eval_df['Language_true'] == 'Hindi').sum() + (eval_df['Language_true'] == 'Bengali').sum() + (eval_df['Language_true'] == 'Telugu').sum()\n",
    "\n",
    "print(\"Hindi Prediction accuracy:\", hindi_acc, \"out of\", ((eval_df['Language_true'] == 'Hindi').sum()))\n",
    "print(\"Bengali Prediction accuracy:\", ben_acc, \"out of\", ((eval_df['Language_true'] == 'Bengali').sum()))\n",
    "print(\"Telugu Prediction accuracy:\", tel_acc, \"out of\", ((eval_df['Language_true'] == 'Telugu').sum()))\n",
    "print(\"Overall accuracy:\", str(round((correct_hindi_count + correct_ben_count + correct_tel_count) * 100 / total_valid, 2)) + '%', \"out of\", total_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Character Stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_3088\\287087302.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eng_df['Native_text'] = eng_df['Text'].apply(remove_english_words)\n"
     ]
    }
   ],
   "source": [
    "# Filter out sentences with 'eng_Latn' tag and strip english characters\n",
    "\n",
    "eng_df = eval_df[eval_df['Language_pred'].isin(eng_categories)]\n",
    "eng_df['Native_text'] = eng_df['Text'].apply(remove_english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Detection Model after english character stripping\n",
    "\n",
    "fixed_outputs = IndicLID_model.batch_predict(eng_df['Native_text'].tolist(), batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_3088\\3591213301.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eng_df['Language_pred'] = fixed_df['Language_pred'].tolist()\n"
     ]
    }
   ],
   "source": [
    "# Join back corrected results to parent df\n",
    "\n",
    "fixed_df = pd.DataFrame(fixed_outputs, columns = ['Text', 'Language_pred', 'Certainity', 'Model'])\n",
    "eng_df['Language_pred'] = fixed_df['Language_pred'].tolist()\n",
    "eng_df.to_excel(r'C:\\Users\\useer\\Downloads\\xyz.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_df = eval_df[~(eval_df['Language_pred'].isin(eng_categories))]\n",
    "eval_df = pd.concat([eval_df, eng_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation after english character removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the count of correct predictions\n",
    "correct_hindi_count = ((eval_df['Language_true'] == 'Hindi') & (eval_df['Language_pred'].isin(hindi_categories))).sum()\n",
    "correct_ben_count = ((eval_df['Language_true'] == 'Bengali') & (eval_df['Language_pred'].isin(ben_categories))).sum()\n",
    "correct_tel_count = ((eval_df['Language_true'] == 'Telugu') & (eval_df['Language_pred'].isin(tel_categories))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi Prediction accuracy: 98.29% out of 234\n",
      "Bengali Prediction accuracy: 100.0% out of 227\n",
      "Telugu Prediction accuracy: 97.84% out of 231\n",
      "Overall accuracy: 98.7% out of 692\n"
     ]
    }
   ],
   "source": [
    "# Estimating accuracy in each language\n",
    "\n",
    "hindi_acc = str(round(correct_hindi_count * 100 / ((eval_df['Language_true'] == 'Hindi').sum()), 2)) + '%'\n",
    "ben_acc = str(round(correct_ben_count * 100 / ((eval_df['Language_true'] == 'Bengali').sum()), 2)) + '%'\n",
    "tel_acc = str(round(correct_tel_count * 100 / ((eval_df['Language_true'] == 'Telugu').sum()), 2)) + '%'\n",
    "total_valid = (eval_df['Language_true'] == 'Hindi').sum() + (eval_df['Language_true'] == 'Bengali').sum() + (eval_df['Language_true'] == 'Telugu').sum()\n",
    "\n",
    "print(\"Hindi Prediction accuracy:\", hindi_acc, \"out of\", ((eval_df['Language_true'] == 'Hindi').sum()))\n",
    "print(\"Bengali Prediction accuracy:\", ben_acc, \"out of\", ((eval_df['Language_true'] == 'Bengali').sum()))\n",
    "print(\"Telugu Prediction accuracy:\", tel_acc, \"out of\", ((eval_df['Language_true'] == 'Telugu').sum()))\n",
    "print(\"Overall accuracy:\", str(round((correct_hindi_count + correct_ben_count + correct_tel_count) * 100 / total_valid, 2)) + '%', \"out of\", total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save erroneous entries\n",
    "\n",
    "rows_not_satisfying_conditions = eval_df[~((eval_df['Language_true'] == 'hi') & (eval_df['Language_pred'].isin(hindi_categories))) &\n",
    "                                           ~((eval_df['Language_true'] == 'bn') & (eval_df['Language_pred'].isin(ben_categories))) &   \n",
    "                                           ~((eval_df['Language_true'] == 'te') & (eval_df['Language_pred'].isin(tel_categories)))]\n",
    "\n",
    "rows_not_satisfying_conditions.to_excel(r'C:\\Users\\useer\\Downloads\\final_detect_check.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
