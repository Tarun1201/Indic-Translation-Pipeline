{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Detect.IndicLID.Inference.ai4bharat.IndicLID import IndicLID                           # Detection\n",
    "\n",
    "IndicLID_model = IndicLID(input_threshold = 0.5, roman_lid_threshold = 0.6)                 # Loading Model with recommended Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset to dict of dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_folder_path = r'F:\\Projects\\translate\\IndicTrans2\\Dataset\\v2\\Translation_val_data'\n",
    "\n",
    "csv_files = os.listdir(val_dataset_folder_path)\n",
    "\n",
    "dfs_dict = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(val_dataset_folder_path, csv_file)\n",
    "    df_name = os.path.splitext(csv_file)[0]\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    df = pd.DataFrame({'Column': lines})\n",
    "    dfs_dict[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'train_bn' has shape: (8604580, 1)\n",
      "DataFrame 'train_bn_en' has shape: (8604580, 1)\n",
      "DataFrame 'train_hi' has shape: (10125706, 1)\n",
      "DataFrame 'train_hi_en' has shape: (10125706, 1)\n",
      "DataFrame 'train_te' has shape: (4946035, 1)\n",
      "DataFrame 'train_te_en' has shape: (4946035, 1)\n"
     ]
    }
   ],
   "source": [
    "for file_name, df in dfs_dict.items():\n",
    "    print(f\"DataFrame '{file_name}' has shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['id'] = range(1, test_size + 1)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['id'] = range(1, test_size + 1)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['id'] = range(1, test_size + 1)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['id'] = range(1, test_size + 1)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['id'] = range(1, test_size + 1)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000['id'] = range(1, test_size + 1)\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\1439055472.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "subset_dict = {}\n",
    "test_size = 10000\n",
    "# Iterate through the original dictionary\n",
    "for file_name, df in dfs_dict.items():\n",
    "    # Get the first 10,000 rows of each DataFrame\n",
    "    df_first_10000 = df.head(test_size)\n",
    "    df_first_10000['Language_true'] = file_name.split('_', 1)[1]\n",
    "    df_first_10000['id'] = range(1, test_size + 1)\n",
    "    df_first_10000.rename(columns={'Column': 'Text'}, inplace=True)\n",
    "    \n",
    "    # Store the new DataFrame in the new dictionary\n",
    "    subset_dict[file_name] = df_first_10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions_and_urls(sentence):\n",
    "\n",
    "    pattern = r'(@\\S+|https://\\S+|#\\S+)'\n",
    "    sentence = sentence.replace('\\n', '')\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    \n",
    "    if '\\n' in sentence:\n",
    "        print(sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    # Define a regular expression pattern to match emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\" \n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    # Use re.sub to replace emojis with an empty string\n",
    "    cleaned_text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english_words(text):\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    non_english_words = [word for word in words if not any(char.isalpha() and ord(char) < 128 for char in word)]\n",
    "    return ' '.join(non_english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_name, df in subset_dict.items():\n",
    "#     df['Text'] = df['Text'].astype(str).apply(remove_mentions_and_urls).apply(remove_emojis)\n",
    "en_dfs = {key: df for key, df in subset_dict.items() if 'en' in key}\n",
    "ind_dfs = {key: df for key, df in subset_dict.items() if 'en' not in key}\n",
    "\n",
    "# Concatenate DataFrames from the filtered dictionary into a single DataFrame\n",
    "merged_en_df = pd.concat(en_dfs.values(), ignore_index=True)\n",
    "merged_ind_df = pd.concat(ind_dfs.values(), ignore_index=True)\n",
    "\n",
    "merged_en_df['Text'] = merged_en_df['Text'].astype(str).apply(remove_mentions_and_urls).apply(remove_emojis)\n",
    "merged_ind_df['Text'] = merged_ind_df['Text'].astype(str).apply(remove_mentions_and_urls).apply(remove_emojis)\n",
    "\n",
    "# Shuffle the rows in random order\n",
    "shuffled_df = shuffle(merged_ind_df)\n",
    "shuffled_seqs = shuffled_df['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = IndicLID_model.batch_predict(shuffled_seqs, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns = ['Text', 'Language_pred', 'Certainity', 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.merge(df, shuffled_df, on='Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language_pred\n",
       "tel_Telu     9988\n",
       "ben_Beng     9467\n",
       "hin_Deva     8724\n",
       "mai_Deva      841\n",
       "asm_Beng      485\n",
       "kas_Deva      138\n",
       "brx_Deva      126\n",
       "mar_Deva       46\n",
       "eng_Latn       41\n",
       "doi_Deva       39\n",
       "san_Deva       34\n",
       "mni_Beng       28\n",
       "nep_Deva       25\n",
       "kok_Deva        7\n",
       "other           5\n",
       "sat_Olch        3\n",
       "tel_Latn        2\n",
       "mni_Meti        2\n",
       "mni_Latn        2\n",
       "kas_Latn        1\n",
       "tam_Tamil       1\n",
       "ori_Latn        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['Language_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_categories = ['hin_Deva', 'mai_Deva', 'mar_Deva', 'san_Deva', 'hin_Latn', 'kas_Deva', 'pan_Latn', 'kok_Deva', 'brx_Deva', 'doi_Deva', 'urd_Latn', 'mai_Latn', 'brx_Latn', 'nep_Deva', 'asm_Latn']\n",
    "ben_categories = ['ben_Beng', 'asm_Beng', 'ben_Latn', 'mni_Beng', 'sat_Olch']\n",
    "tel_categories = ['tel_Telu', 'tel_Latn']\n",
    "eng_categories = ['eng_Latn', 'mni_Latn', 'kok_Latn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_28108\\3740419675.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eng_df['Native_text'] = eng_df['Text'].apply(remove_english_words)\n"
     ]
    }
   ],
   "source": [
    "eng_df = eval_df[eval_df['Language_pred'] == 'eng_Latn']\n",
    "eng_df['Native_text'] = eng_df['Text'].apply(remove_english_words)\n",
    "fixed_outputs = IndicLID_model.batch_predict(eng_df['Native_text'], batch_size = 128)\n",
    "fixed_df = pd.DataFrame(fixed_outputs, columns = ['Text', 'Language_pred', 'Certainity', 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_df.to_csv(r'C:\\Users\\useer\\Downloads\\eng_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language_pred</th>\n",
       "      <th>Certainity</th>\n",
       "      <th>Model</th>\n",
       "      <th>Language_true</th>\n",
       "      <th>id</th>\n",
       "      <th>Native_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\"\" उन्होंने कहा, \"\"मैं यहां जोर देकर कहना चाह...</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>IndicLID-FTN</td>\n",
       "      <td>hi</td>\n",
       "      <td>9966</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>কারও কাছে জীবনের অভ্যেস এক লহমায় বদলে যাওয়া।</td>\n",
       "      <td>ben_Beng</td>\n",
       "      <td>1.000049</td>\n",
       "      <td>IndicLID-FTN</td>\n",
       "      <td>bn</td>\n",
       "      <td>8871</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>అలాంటి వారిని పొగడటం లేదు.</td>\n",
       "      <td>tel_Telu</td>\n",
       "      <td>1.000050</td>\n",
       "      <td>IndicLID-FTN</td>\n",
       "      <td>te</td>\n",
       "      <td>7224</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ঘটনায় জড়িত একজনকে আটক করা হয়েছে।</td>\n",
       "      <td>ben_Beng</td>\n",
       "      <td>1.000047</td>\n",
       "      <td>IndicLID-FTN</td>\n",
       "      <td>bn</td>\n",
       "      <td>5316</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>తిరిగి తిరిగీ తిప్పలే!</td>\n",
       "      <td>tel_Telu</td>\n",
       "      <td>1.000025</td>\n",
       "      <td>IndicLID-FTN</td>\n",
       "      <td>te</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001</th>\n",
       "      <td>দর্শী এ,আর The Gallant Defender সিং পি, The Go...</td>\n",
       "      <td>ben_Beng</td>\n",
       "      <td>0.668298</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>bn</td>\n",
       "      <td>3699</td>\n",
       "      <td>দর্শী এ , আর সিং পি ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002</th>\n",
       "      <td>\"\"\"The BJP, however, has made it clear that it...</td>\n",
       "      <td>ben_Beng</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>bn</td>\n",
       "      <td>8008</td>\n",
       "      <td>`` `` '' , , ’ . `` `` , তবে তিনি এও পরিষ্কার ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30003</th>\n",
       "      <td>इस खबर को अंग्रेजी में पढ़ें- Behind ISI’s ren...</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>hi</td>\n",
       "      <td>4953</td>\n",
       "      <td>इस खबर को अंग्रेजी में पढ़ें- ’ : 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30004</th>\n",
       "      <td>పూర్వ్ అనే దక్షిణ పూర్వ్ ఈంగ్లేన్డ్City in Eas...</td>\n",
       "      <td>tel_Telu</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>te</td>\n",
       "      <td>8674</td>\n",
       "      <td>పూర్వ్ అనే దక్షిణ పూర్వ్ ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30005</th>\n",
       "      <td>यह बन जाता है more interesting या less interes...</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>0.844818</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>hi</td>\n",
       "      <td>7428</td>\n",
       "      <td>यह बन जाता है या .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30006 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Language_pred  \\\n",
       "0      \"\"\" उन्होंने कहा, \"\"मैं यहां जोर देकर कहना चाह...      hin_Deva   \n",
       "1           কারও কাছে জীবনের অভ্যেস এক লহমায় বদলে যাওয়া।      ben_Beng   \n",
       "2                             అలాంటి వారిని పొగడటం లేదు.      tel_Telu   \n",
       "3                       ঘটনায় জড়িত একজনকে আটক করা হয়েছে।      ben_Beng   \n",
       "4                                 తిరిగి తిరిగీ తిప్పలే!      tel_Telu   \n",
       "...                                                  ...           ...   \n",
       "30001  দর্শী এ,আর The Gallant Defender সিং পি, The Go...      ben_Beng   \n",
       "30002  \"\"\"The BJP, however, has made it clear that it...      ben_Beng   \n",
       "30003  इस खबर को अंग्रेजी में पढ़ें- Behind ISI’s ren...      hin_Deva   \n",
       "30004  పూర్వ్ అనే దక్షిణ పూర్వ్ ఈంగ్లేన్డ్City in Eas...      tel_Telu   \n",
       "30005  यह बन जाता है more interesting या less interes...      hin_Deva   \n",
       "\n",
       "       Certainity         Model Language_true    id  \\\n",
       "0        0.999996  IndicLID-FTN            hi  9966   \n",
       "1        1.000049  IndicLID-FTN            bn  8871   \n",
       "2        1.000050  IndicLID-FTN            te  7224   \n",
       "3        1.000047  IndicLID-FTN            bn  5316   \n",
       "4        1.000025  IndicLID-FTN            te   365   \n",
       "...           ...           ...           ...   ...   \n",
       "30001    0.668298  IndicLID-FTR            bn  3699   \n",
       "30002    0.999888  IndicLID-FTR            bn  8008   \n",
       "30003    0.999575  IndicLID-FTR            hi  4953   \n",
       "30004    0.998167  IndicLID-FTR            te  8674   \n",
       "30005    0.844818  IndicLID-FTR            hi  7428   \n",
       "\n",
       "                                             Native_text  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "30001                              দর্শী এ , আর সিং পি ,  \n",
       "30002  `` `` '' , , ’ . `` `` , তবে তিনি এও পরিষ্কার ...  \n",
       "30003                इस खबर को अंग्रेजी में पढ़ें- ’ : 2  \n",
       "30004                         పూర్వ్ అనే దక్షిణ పూర్వ్ ,  \n",
       "30005                                 यह बन जाता है या .  \n",
       "\n",
       "[30006 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_df['Language_pred'] = fixed_df['Language_pred'].tolist()\n",
    "\n",
    "eval_df = eval_df[~(eval_df['Language_pred'] == 'eng_Latn')]\n",
    "eval_df = pd.concat([eval_df, eng_df], ignore_index=True)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_hindi_count = ((eval_df['Language_true'] == 'hi') & (eval_df['Language_pred'].isin(hindi_categories))).sum()\n",
    "correct_ben_count = ((eval_df['Language_true'] == 'bn') & (eval_df['Language_pred'].isin(ben_categories))).sum()\n",
    "correct_tel_count = ((eval_df['Language_true'] == 'te') & (eval_df['Language_pred'].isin(tel_categories))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi Prediction accuracy: 99.95001999200319 out of 10004\n",
      "Bengali Prediction accuracy: 99.97000599880025 out of 10002\n",
      "Telugu Prediction accuracy: 99.93 out of 10000\n",
      "Overall accuracy: 99.9500099980004 out of 30006\n"
     ]
    }
   ],
   "source": [
    "hindi_acc = correct_hindi_count * 100 / ((eval_df['Language_true'] == 'hi').sum())\n",
    "ben_acc = correct_ben_count * 100 / ((eval_df['Language_true'] == 'bn').sum())\n",
    "tel_acc = correct_tel_count * 100 / ((eval_df['Language_true'] == 'te').sum())\n",
    "total_valid = (eval_df['Language_true'] == 'hi').sum() + (eval_df['Language_true'] == 'bn').sum() + (eval_df['Language_true'] == 'te').sum()\n",
    "\n",
    "print(\"Hindi Prediction accuracy:\", hindi_acc, \"out of\", ((eval_df['Language_true'] == 'hi').sum()))\n",
    "print(\"Bengali Prediction accuracy:\", ben_acc, \"out of\", ((eval_df['Language_true'] == 'bn').sum()))\n",
    "print(\"Telugu Prediction accuracy:\", tel_acc, \"out of\", ((eval_df['Language_true'] == 'te').sum()))\n",
    "print(\"Overall accuracy:\", (correct_hindi_count + correct_ben_count + correct_tel_count) * 100 / total_valid, \"out of\", total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(r'C:\\Users\\useer\\Downloads\\eval_df.csv')\n",
    "merged_en_df.to_csv(r'C:\\Users\\useer\\Downloads\\en_ref_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_not_satisfying_conditions = eval_df[~((eval_df['Language_true'] == 'hi') & (eval_df['Language_pred'].isin(hindi_categories))) &\n",
    "                                           ~((eval_df['Language_true'] == 'bn') & (eval_df['Language_pred'].isin(ben_categories))) &\n",
    "                                           ~((eval_df['Language_true'] == 'te') & (eval_df['Language_pred'].isin(tel_categories)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_not_satisfying_conditions.to_excel(r'C:\\Users\\useer\\Downloads\\erroneous_entries_detection_iter3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_not_satisfying_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.engine import Model as IndicTrans2                       # Translation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sentencepiece model for SRC and TGT\n",
      "Initializing model for translation\n",
      "WARNING:tensorflow:From f:\\Projects\\translate\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 11:42:27 | INFO | fairseq.tasks.translation | [SRC] dictionary: 122706 types\n",
      "2024-02-24 11:42:27 | INFO | fairseq.tasks.translation | [TGT] dictionary: 32296 types\n"
     ]
    }
   ],
   "source": [
    "IndicTrans2_model = IndicTrans2(\"models/indic-en-preprint/fairseq_model\", model_type=\"fairseq\")# , device='cuda') #kernel crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eng_ref_translation_df = pd.read_csv(r'C:\\Users\\useer\\Downloads\\en_ref_df.csv')\n",
    "# input_df = pd.read_csv(r'C:\\Users\\useer\\Downloads\\eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(r'C:\\Users\\useer\\Downloads\\eng_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['match_id'] = input_df['Language_true'] + '_en_' + input_df['id'].astype(str)\n",
    "eng_ref_translation_df['match_id'] = eng_ref_translation_df['Language_true'] + '_' + eng_ref_translation_df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Language_true</th>\n",
       "      <th>id</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The International Civil Aviation Organisation ...</td>\n",
       "      <td>bn_en</td>\n",
       "      <td>1</td>\n",
       "      <td>bn_en_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>They can be deactivated using the control pane...</td>\n",
       "      <td>bn_en</td>\n",
       "      <td>2</td>\n",
       "      <td>bn_en_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>He was born at Ulail in Dhaka district of Beng...</td>\n",
       "      <td>bn_en</td>\n",
       "      <td>3</td>\n",
       "      <td>bn_en_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Atra Gilatola Union</td>\n",
       "      <td>bn_en</td>\n",
       "      <td>4</td>\n",
       "      <td>bn_en_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>He is the father of five daughters.</td>\n",
       "      <td>bn_en</td>\n",
       "      <td>5</td>\n",
       "      <td>bn_en_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0  The International Civil Aviation Organisation ...   \n",
       "1           1  They can be deactivated using the control pane...   \n",
       "2           2  He was born at Ulail in Dhaka district of Beng...   \n",
       "3           3                                Atra Gilatola Union   \n",
       "4           4                He is the father of five daughters.   \n",
       "\n",
       "  Language_true  id match_id  \n",
       "0         bn_en   1  bn_en_1  \n",
       "1         bn_en   2  bn_en_2  \n",
       "2         bn_en   3  bn_en_3  \n",
       "3         bn_en   4  bn_en_4  \n",
       "4         bn_en   5  bn_en_5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ref_translation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Language_pred</th>\n",
       "      <th>Certainity</th>\n",
       "      <th>Model</th>\n",
       "      <th>Language_true</th>\n",
       "      <th>id</th>\n",
       "      <th>Native_text</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>522</td>\n",
       "      <td>Russia in Figures (PDF) (প্রতিবেদন)।</td>\n",
       "      <td>ben_Beng</td>\n",
       "      <td>0.998066</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>bn</td>\n",
       "      <td>506</td>\n",
       "      <td>( ) ( প্রতিবেদন ) ।</td>\n",
       "      <td>bn_en_506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947</td>\n",
       "      <td>अंग्रेजी में भी पढ़ें: LSR starts special law ...</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>0.848665</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>hi</td>\n",
       "      <td>5384</td>\n",
       "      <td>अंग्रेजी में भी पढ़ें :</td>\n",
       "      <td>hi_en_5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2664</td>\n",
       "      <td>com, 29 नवंबर 2019 को Jagran ‘HiTech Awards 20...</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>0.830920</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>hi</td>\n",
       "      <td>7292</td>\n",
       "      <td>, 29 नवंबर 2019 को ‘ 2019 का आयोजन कर रही है।</td>\n",
       "      <td>hi_en_7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2960</td>\n",
       "      <td>\"উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার ক...</td>\n",
       "      <td>ben_Beng</td>\n",
       "      <td>5.824115</td>\n",
       "      <td>IndicLID-BERT</td>\n",
       "      <td>bn</td>\n",
       "      <td>8883</td>\n",
       "      <td>`` উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার...</td>\n",
       "      <td>bn_en_8883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3303</td>\n",
       "      <td>White House Threatens To Suspend Again Cnn Rep...</td>\n",
       "      <td>hin_Deva</td>\n",
       "      <td>0.622242</td>\n",
       "      <td>IndicLID-FTR</td>\n",
       "      <td>hi</td>\n",
       "      <td>960</td>\n",
       "      <td>| व्हाइट हाउस दोबारा निलंबित कर सकता है के जिम...</td>\n",
       "      <td>hi_en_960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0         522               Russia in Figures (PDF) (প্রতিবেদন)।   \n",
       "1         947  अंग्रेजी में भी पढ़ें: LSR starts special law ...   \n",
       "2        2664  com, 29 नवंबर 2019 को Jagran ‘HiTech Awards 20...   \n",
       "3        2960  \"উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার ক...   \n",
       "4        3303  White House Threatens To Suspend Again Cnn Rep...   \n",
       "\n",
       "  Language_pred  Certainity          Model Language_true    id  \\\n",
       "0      ben_Beng    0.998066   IndicLID-FTR            bn   506   \n",
       "1      hin_Deva    0.848665   IndicLID-FTR            hi  5384   \n",
       "2      hin_Deva    0.830920   IndicLID-FTR            hi  7292   \n",
       "3      ben_Beng    5.824115  IndicLID-BERT            bn  8883   \n",
       "4      hin_Deva    0.622242   IndicLID-FTR            hi   960   \n",
       "\n",
       "                                         Native_text    match_id  \n",
       "0                                ( ) ( প্রতিবেদন ) ।   bn_en_506  \n",
       "1                            अंग्रेजी में भी पढ़ें :  hi_en_5384  \n",
       "2      , 29 नवंबर 2019 को ‘ 2019 का आयोजन कर रही है।  hi_en_7292  \n",
       "3  `` উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার...  bn_en_8883  \n",
       "4  | व्हाइट हाउस दोबारा निलंबित कर सकता है के जिम...   hi_en_960  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_categories = ['hin_Deva', 'mai_Deva', 'mar_Deva', 'san_Deva', 'hin_Latn', 'kas_Deva', 'pan_Latn', 'kok_Deva', 'brx_Deva', 'doi_Deva', 'urd_Latn', 'mai_Latn', 'brx_Latn', 'nep_Deva']\n",
    "ben_categories = ['ben_Beng', 'asm_Beng', 'ben_Latn', 'mni_Beng']\n",
    "tel_categories = ['tel_Telu', 'tel_Latn']\n",
    "eng_categories = ['eng_Latn', 'mni_Latn', 'kok_Latn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_sentences = input_df[input_df['Language_pred'].isin(hindi_categories)][['Text', 'match_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "filtered_hindi_list = hindi_sentences['Text'].tolist()\n",
    "\n",
    "for sent in filtered_hindi_list:\n",
    "    if len(sent) > 256:\n",
    "        filtered_hindi_list.remove(sent)\n",
    "\n",
    "print(len(filtered_hindi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 16:58:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
      "2024-01-04 16:58:17 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
      "2024-01-04 16:58:17 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
      "2024-01-04 16:58:17 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n"
     ]
    }
   ],
   "source": [
    "hindi_translated = IndicTrans2_model.batch_translate(filtered_hindi_list, \"hin_Deva\", \"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_x</th>\n",
       "      <th>match_id</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text_y</th>\n",
       "      <th>Language_true</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अंग्रेजी में भी पढ़ें: LSR starts special law ...</td>\n",
       "      <td>hi_en_5384</td>\n",
       "      <td>Also read: LSR starts special law course on wo...</td>\n",
       "      <td>15383</td>\n",
       "      <td>LSR starts special law course on women's issues</td>\n",
       "      <td>hi_en</td>\n",
       "      <td>5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com, 29 नवंबर 2019 को Jagran ‘HiTech Awards 20...</td>\n",
       "      <td>hi_en_7292</td>\n",
       "      <td>JAGRAN 'HiTech Awards 2019 is being held on 29...</td>\n",
       "      <td>17291</td>\n",
       "      <td>New Delhi | Jagran Technology Desk: Digital me...</td>\n",
       "      <td>hi_en</td>\n",
       "      <td>7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White House Threatens To Suspend Again Cnn Rep...</td>\n",
       "      <td>hi_en_960</td>\n",
       "      <td>White House Threatens to Suspend CNN Reporter ...</td>\n",
       "      <td>10959</td>\n",
       "      <td>White House suspends press credentials of CNN ...</td>\n",
       "      <td>hi_en</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>सरणी नाम (_N):New RAID Array</td>\n",
       "      <td>hi_en_8809</td>\n",
       "      <td>_ Array name: New RAID Array</td>\n",
       "      <td>18808</td>\n",
       "      <td>Array _Name:</td>\n",
       "      <td>hi_en</td>\n",
       "      <td>8809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>साथियो, यहां आने से पहले मैं International ric...</td>\n",
       "      <td>hi_en_5292</td>\n",
       "      <td>Friends, Before coming here, I had also visite...</td>\n",
       "      <td>15291</td>\n",
       "      <td>Before coming here, I had visited the campus o...</td>\n",
       "      <td>hi_en</td>\n",
       "      <td>5292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text_x    match_id  \\\n",
       "0  अंग्रेजी में भी पढ़ें: LSR starts special law ...  hi_en_5384   \n",
       "1  com, 29 नवंबर 2019 को Jagran ‘HiTech Awards 20...  hi_en_7292   \n",
       "2  White House Threatens To Suspend Again Cnn Rep...   hi_en_960   \n",
       "3                       सरणी नाम (_N):New RAID Array  hi_en_8809   \n",
       "4  साथियो, यहां आने से पहले मैं International ric...  hi_en_5292   \n",
       "\n",
       "                                     translated_text  Unnamed: 0  \\\n",
       "0  Also read: LSR starts special law course on wo...       15383   \n",
       "1  JAGRAN 'HiTech Awards 2019 is being held on 29...       17291   \n",
       "2  White House Threatens to Suspend CNN Reporter ...       10959   \n",
       "3                       _ Array name: New RAID Array       18808   \n",
       "4  Friends, Before coming here, I had also visite...       15291   \n",
       "\n",
       "                                              Text_y Language_true    id  \n",
       "0    LSR starts special law course on women's issues         hi_en  5384  \n",
       "1  New Delhi | Jagran Technology Desk: Digital me...         hi_en  7292  \n",
       "2  White House suspends press credentials of CNN ...         hi_en   960  \n",
       "3                                       Array _Name:         hi_en  8809  \n",
       "4  Before coming here, I had visited the campus o...         hi_en  5292  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_sentences = hindi_sentences[hindi_sentences['Text'].isin(filtered_hindi_list)]\n",
    "hindi_sentences['translated_text'] = hindi_translated\n",
    "hindi_val_df = pd.merge(hindi_sentences, eng_ref_translation_df, on='match_id', how='inner')\n",
    "hindi_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_val_df['Text_x'].to_excel(r'C:\\Users\\useer\\Downloads\\gtrans_eng_hin_labels.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Also read in English: LSR starts special law ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>com is organizing Jagran'HiTech Awards 2019 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>White House Threatens To Suspend Again Cnn Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Array Name (_N):New RAID Array</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Friends, before coming here, I had also gone ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             text_x\n",
       "0           0   Also read in English: LSR starts special law ...\n",
       "1           1   com is organizing Jagran'HiTech Awards 2019 o...\n",
       "2           2   White House Threatens To Suspend Again Cnn Re...\n",
       "3           3                     Array Name (_N):New RAID Array\n",
       "4           4   Friends, before coming here, I had also gone ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_excel(r'C:\\Users\\useer\\Downloads\\gtrans_eng_hin_labels_translated.xlsx')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'गलतफहमी के कारण हुआ झगड़ा'</td>\n",
       "      <td>'The fight happened due to misunderstanding'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>इसके अलावा यह अभ्‍यास दोनों सेनाओं के मध्‍य सम...</td>\n",
       "      <td>Additionally, the exercise will mark a milesto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>हे परमेश्‍वर जब मैं बूढ़ा हो जाऊं, और मेरे बाल...</td>\n",
       "      <td>God, even when I grow old and my hair grows gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>इसी बात को लेकर दोनों पक्षों में जमकर मारामारी...</td>\n",
       "      <td>There was a fierce fight between the two sides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>कभी - कभी जीवन के तनावों और खिंचावों के कारण ल...</td>\n",
       "      <td>Sometimes, due to the stresses and strains of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0                        'गलतफहमी के कारण हुआ झगड़ा'   \n",
       "1           1  इसके अलावा यह अभ्‍यास दोनों सेनाओं के मध्‍य सम...   \n",
       "2           2  हे परमेश्‍वर जब मैं बूढ़ा हो जाऊं, और मेरे बाल...   \n",
       "3           3  इसी बात को लेकर दोनों पक्षों में जमकर मारामारी...   \n",
       "4           4  कभी - कभी जीवन के तनावों और खिंचावों के कारण ल...   \n",
       "\n",
       "                                              text_x  \n",
       "0       'The fight happened due to misunderstanding'  \n",
       "1  Additionally, the exercise will mark a milesto...  \n",
       "2  God, even when I grow old and my hair grows gr...  \n",
       "3  There was a fierce fight between the two sides...  \n",
       "4  Sometimes, due to the stresses and strains of ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_excel(r'C:\\Users\\useer\\Downloads\\hindi_text_gtrans.xlsx')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu_score(reference, translation):\n",
    "    reference_tokenized = [reference.split()]\n",
    "    translation_tokenized = translation.split()\n",
    "\n",
    "    bleu_score = sentence_bleu(reference_tokenized, translation_tokenized)\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu_scores(candidate_list, reference_list):\n",
    "    # candidate_list: List of translated sentences\n",
    "    # reference_list: List of reference sentences\n",
    "\n",
    "    # Tokenize sentences\n",
    "    candidate_tokenized = [sentence.split() for sentence in candidate_list]\n",
    "    reference_tokenized = [[sentence.split()] for sentence in reference_list]\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = corpus_bleu(reference_tokenized, candidate_tokenized)\n",
    "\n",
    "    return bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score of IndicTrans2: 0.22047813494583085\n"
     ]
    }
   ],
   "source": [
    "# Gtest data\n",
    "translations = hindi_val_df['translated_text'].tolist()\n",
    "reference_sentences = hindi_val_df['Text_y'].tolist()\n",
    "\n",
    "bleu_score = calculate_bleu_scores(translations, reference_sentences)\n",
    "print(f\"BLEU Score of IndicTrans2: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score of Google Translate: 0.19120931692401408\n"
     ]
    }
   ],
   "source": [
    "# Gtest data\n",
    "translations = y['text_x'].tolist()\n",
    "reference_sentences = hindi_val_df['Text_y'].tolist()\n",
    "\n",
    "bleu_score = calculate_bleu_scores(translations, reference_sentences)\n",
    "print(f\"BLEU Score of Google Translate: {bleu_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
